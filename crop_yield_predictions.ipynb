{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnatnib/crop_yield_prediction/blob/main/crop_yield_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGXIW7LCwmd5"
      },
      "source": [
        "# **Crop Yield Prediction - Regresi Interpolasi**\n",
        "**Anggota Kelompok:**\n",
        "\n",
        "\n",
        "*   Bintang Syafrian Rizal - 24060122120031\n",
        "*   Awang Pratama Mulya    - 24060122120039\n",
        "*   Irfan Mursyid\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zSxyd2fk-W1F"
      },
      "outputs": [],
      "source": [
        "#import dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JOXdmg-fCBlv",
        "outputId": "9056aa9c-6dd7-4ac0-f570-8515d4ec9c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'yield_df.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-91f553164858>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yield_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yield_df.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('yield_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPKQcYIwCiOR"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJPOoiyy72Pk"
      },
      "outputs": [],
      "source": [
        "def stratified_crop_sampling(df, n_samples=2000, random_state=42):\n",
        "    \"\"\"\n",
        "    Perform stratified sampling on crop yield data to maintain representation\n",
        "    across different areas and items (crops).\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "        The original dataset containing crop yield information\n",
        "    n_samples : int\n",
        "        Number of samples to select (default: 2000)\n",
        "    random_state : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pandas DataFrame\n",
        "        Sampled dataset maintaining proportions of areas and items\n",
        "    \"\"\"\n",
        "    # Calculate the proportion of each Area-Item combination\n",
        "    groupby_counts = df.groupby(['Area', 'Item']).size()\n",
        "    total_records = len(df)\n",
        "\n",
        "    # Calculate number of samples to take from each stratum\n",
        "    samples_per_stratum = (groupby_counts / total_records * n_samples).round().astype(int)\n",
        "\n",
        "    # Adjust to ensure we get exactly n_samples\n",
        "    while samples_per_stratum.sum() != n_samples:\n",
        "        if samples_per_stratum.sum() > n_samples:\n",
        "            # Remove one sample from the largest stratum\n",
        "            max_stratum = samples_per_stratum.idxmax()\n",
        "            samples_per_stratum[max_stratum] -= 1\n",
        "        else:\n",
        "            # Add one sample to the smallest non-zero stratum\n",
        "            min_stratum = samples_per_stratum[samples_per_stratum > 0].idxmin()\n",
        "            samples_per_stratum[min_stratum] += 1\n",
        "\n",
        "    # Sample from each stratum\n",
        "    sampled_data = []\n",
        "    for (area, item), n in samples_per_stratum.items():\n",
        "        if n > 0:\n",
        "            stratum = df[(df['Area'] == area) & (df['Item'] == item)]\n",
        "            # If n is larger than the stratum size, take all records\n",
        "            if n >= len(stratum):\n",
        "                sampled_data.append(stratum)\n",
        "            else:\n",
        "                sampled = stratum.sample(n=n, random_state=random_state)\n",
        "                sampled_data.append(sampled)\n",
        "\n",
        "    # Combine all sampled data\n",
        "    final_sample = pd.concat(sampled_data, axis=0)\n",
        "\n",
        "    return final_sample\n",
        "\n",
        "def verify_sampling(original_df, sampled_df):\n",
        "    \"\"\"\n",
        "    Verify the quality of sampling by comparing distributions\n",
        "    of key features in original and sampled datasets.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    original_df : pandas DataFrame\n",
        "        The original dataset\n",
        "    sampled_df : pandas DataFrame\n",
        "        The sampled dataset\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary containing comparison metrics\n",
        "    \"\"\"\n",
        "    metrics = {\n",
        "        'total_samples': len(sampled_df),\n",
        "        'unique_areas': {\n",
        "            'original': len(original_df['Area'].unique()),\n",
        "            'sampled': len(sampled_df['Area'].unique())\n",
        "        },\n",
        "        'unique_items': {\n",
        "            'original': len(original_df['Item'].unique()),\n",
        "            'sampled': len(sampled_df['Item'].unique())\n",
        "        },\n",
        "        'year_range': {\n",
        "            'original': (original_df['Year'].min(), original_df['Year'].max()),\n",
        "            'sampled': (sampled_df['Year'].min(), sampled_df['Year'].max())\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPTGV7E0wBEs"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_gSv9dTCxI6"
      },
      "outputs": [],
      "source": [
        "df.drop('Unnamed: 0', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3Rncl8LtnZ1"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl-BXpOztpM9"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8RffuHntrH-"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3hP5Q-tuNd1"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWjPRtU1ufvB"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_n52TA2unLN"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1ZtJURFuo_g"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKY6ndBhurJh"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRWFm7vXvAqo"
      },
      "outputs": [],
      "source": [
        "numerical_df = df.select_dtypes(include=np.number)\n",
        "correlation_matrix = numerical_df.corr()\n",
        "\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdT6uHYkyO0x"
      },
      "source": [
        "# **Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiLyfPySvBhh"
      },
      "outputs": [],
      "source": [
        "len(df['Area'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTutufIE72Pn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,4))\n",
        "g1 = sns.countplot(x=df['Area'], hue=df['Area'], legend=False)\n",
        "g1.set_title('Distribution of Area')\n",
        "\n",
        "g1.set_xticklabels(g1.get_xticklabels(), rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79RC66ux72Pn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "g2 = sns.countplot(y=df['Item'], hue=df['Item'], legend=False)\n",
        "g2.set_title('Distribution of Item')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfy_EkhE72Pn"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 3))\n",
        "\n",
        "g1=sns.histplot(df[\"average_rain_fall_mm_per_year\"], kde=True, ax=axes[0])\n",
        "g2=sns.histplot(df[\"pesticides_tonnes\"], kde=True, ax=axes[1], label='Data')\n",
        "g3=sns.histplot(df[\"avg_temp\"], kde=True, ax=axes[2], label='Data')\n",
        "\n",
        "\n",
        "g1.set_title(\"Distribution of average_rain_fall_mm_per_year\")\n",
        "g2.set_title(\"Distribution of pesticides_tonnes\")\n",
        "g3.set_title(\"Distribution of avg_temp\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImvGWDJE72Pn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "g=sns.histplot(df[\"hg/ha_yield\"], kde=True, label='Data')\n",
        "g.set_title(\"Distribution of target column: hg/ha_yield\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fr9ADU_72Pn"
      },
      "outputs": [],
      "source": [
        "#Correlation Matrix\n",
        "corr_matrix = df.drop(['Area', 'Item'], axis=1).corr()\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=cmap, fmt=\".2f\", center = 0, annot_kws={\"size\": 12}).set_title('Correlation Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ2P61Vl72Po"
      },
      "outputs": [],
      "source": [
        "(df['Area'].value_counts() < 400).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccEdiDFL72Po"
      },
      "outputs": [],
      "source": [
        "country = df['Area'].unique()\n",
        "yield_per_country = []\n",
        "for state in country:\n",
        "    yield_per_country.append(df[df['Area'] == state]['hg/ha_yield'].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmjI47np72Po"
      },
      "outputs": [],
      "source": [
        "df['hg/ha_yield'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQVU7ppV72Po"
      },
      "outputs": [],
      "source": [
        "#Yield per Country\n",
        "area_dropdown = widgets.Dropdown(options=df['Area'].unique(), description='Area:')\n",
        "item_dropdown = widgets.Dropdown(options=df['Item'].unique(), description='Item:')\n",
        "\n",
        "def plot_data(area, item):\n",
        "    plt.figure(figsize=(10,6))\n",
        "    temp_df = df[(df['Area'] == area) & (df['Item'] == item)]\n",
        "    plt.plot(temp_df['Year'], temp_df['hg/ha_yield'])\n",
        "    plt.title(f'hg/ha_yield over the years for {item} in {area}')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('hg/ha_yield')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "widgets.interactive(plot_data, area=area_dropdown, item=item_dropdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YemQUB7l72Po"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,25))\n",
        "sns.barplot(y=country, x=yield_per_country, hue=country, dodge=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFNt9PyN72Po"
      },
      "outputs": [],
      "source": [
        "crops = df['Item'].unique()\n",
        "yield_per_crop = []\n",
        "for crop in crops:\n",
        "    yield_per_crop.append(df[df['Item'] == crop]['hg/ha_yield'].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTqhkRM272Po"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,25))\n",
        "sns.barplot(y=crops, x=yield_per_crop, hue=crops, dodge=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35670Mti72Pp"
      },
      "source": [
        "# **Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSijSaTt72Pp"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDYE0Q-r72Pp"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_SfL4lT72Pp"
      },
      "outputs": [],
      "source": [
        "col = ['Year', 'average_rain_fall_mm_per_year','pesticides_tonnes', 'avg_temp', 'Area', 'Item', 'hg/ha_yield']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dSOOzVv72Pp"
      },
      "outputs": [],
      "source": [
        "df = df[col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO2qgbMW72Pp"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCzE9cMU72Pp"
      },
      "outputs": [],
      "source": [
        "X = df.drop('hg/ha_yield', axis=1)\n",
        "y = df['hg/ha_yield']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU9S3j9_72Pp"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO7S42gP72Pq"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQXeAgt_72Pt"
      },
      "outputs": [],
      "source": [
        "sampled_df = stratified_crop_sampling(df, n_samples=2000)\n",
        "X = sampled_df.drop('hg/ha_yield', axis=1)\n",
        "y = sampled_df['hg/ha_yield']\n",
        "\n",
        "# Split the sampled data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PggBGEZ72Pt"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "ohe = OneHotEncoder(drop='first')\n",
        "scale = StandardScaler()\n",
        "numeric_features = ['Year', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']\n",
        "categorical_features = ['Area', 'Item']\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('StandardScale', StandardScaler(), numeric_features),\n",
        "        ('OneHotEncode', OneHotEncoder(drop='first', sparse=False), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex-hRHcR72Pt"
      },
      "outputs": [],
      "source": [
        "X_train_dummy = preprocessor.fit_transform(X_train)\n",
        "X_test_dummy = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1KAmGWa72Pu"
      },
      "outputs": [],
      "source": [
        "preprocessor.get_feature_names_out(col[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cl_bUs772Pu"
      },
      "source": [
        "# **Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCypLpjV72Pu"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZtZmp7A72Pu"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'LinearRegression' : LinearRegression(),\n",
        "    'Decision Tree' : DecisionTreeRegressor(),\n",
        "    'KNN' : KNeighborsRegressor()\n",
        "}\n",
        "\n",
        "scores = []\n",
        "for name, md in models.items():\n",
        "    md.fit(X_train_dummy, y_train)\n",
        "    y_predict = md.predict(X_test_dummy)\n",
        "    scores.append({\n",
        "        'Model': name,\n",
        "        'Scores' : md.score(X_test_dummy, y_test),\n",
        "        'MAE': mean_absolute_error(y_test, y_predict),\n",
        "        'R2': r2_score(y_test, y_predict)\n",
        "    })\n",
        "    print(f\"{name} - Scores: {md.score(X_test_dummy,y_test)} , MAE: {mean_absolute_error(y_test, y_predict)}, R2: {r2_score(y_test, y_predict)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KW0v1Wg72Pu"
      },
      "outputs": [],
      "source": [
        "#Table views of the Scores, MAE and R2\n",
        "scores = pd.DataFrame(scores, columns=['Model', 'Scores', 'MAE', 'R2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDQaGhBn72Pu"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qdp3V_Z972Pv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "ax = sns.barplot(x='Model', y='Scores', data=scores)\n",
        "ax.bar_label(ax.containers[0])\n",
        "ax.set_title('Model Scores')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hhvvOla72Pv"
      },
      "outputs": [],
      "source": [
        "dtr = DecisionTreeRegressor()\n",
        "dtr.fit(X_train_dummy, y_train)\n",
        "dtr.predict(X_test_dummy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ_PMQcc72Pv"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV2Jn27672Pv"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc6g_bch72Pv"
      },
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8FxrFZ872Pv"
      },
      "outputs": [],
      "source": [
        "def prediction(Year, average_rain_fall_mm_per_year, pesticides_tonnes, avg_temp, Area, Item):\n",
        "    input_data = pd.DataFrame({\n",
        "        'Year': [Year],\n",
        "        'average_rain_fall_mm_per_year': [average_rain_fall_mm_per_year],\n",
        "        'pesticides_tonnes': [pesticides_tonnes],\n",
        "        'avg_temp': [avg_temp],\n",
        "        'Area': [Area],\n",
        "        'Item': [Item]\n",
        "    })\n",
        "\n",
        "    # Transform the features\n",
        "    transform_features = preprocessor.transform(input_data)\n",
        "\n",
        "    # Make prediction\n",
        "    predicted_yield = dtr.predict(transform_features)\n",
        "\n",
        "    return predicted_yield[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LgIq5D-72Pw"
      },
      "outputs": [],
      "source": [
        "result = prediction(1990,1485.0,121.0,16.37,'Albania','Potatoes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VotAZUjB72Pw"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}